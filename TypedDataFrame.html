
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Proof of Concept: TypedDataFrame Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.2">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="Cats.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="FeatureOverview.html">
            
                <a href="FeatureOverview.html">
            
                    
                    TypedDataset: Feature Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="TypedDatasetVsSparkDataset.html">
            
                <a href="TypedDatasetVsSparkDataset.html">
            
                    
                    Comparing TypedDatasets with Spark's Datasets
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="TypedEncoder.html">
            
                <a href="TypedEncoder.html">
            
                    
                    Typed Encoders in Frameless
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="Injection.html">
            
                <a href="Injection.html">
            
                    
                    Injection: Creating Custom Encoders
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="Job.html">
            
                <a href="Job.html">
            
                    
                    Job[A]
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="Cats.html">
            
                <a href="Cats.html">
            
                    
                    Using Cats with RDDs
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.8" data-path="TypedDataFrame.html">
            
                <a href="TypedDataFrame.html">
            
                    
                    Proof of Concept: TypedDataFrame
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Proof of Concept: TypedDataFrame</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="proof-of-concept-typeddataframe">Proof of Concept: TypedDataFrame</h1>
<p><code>TypedDataFrame</code> is the API developed in the early stages of frameless to manipulate Spark <code>DataFrame</code>s in a type-safe manner. With the introduction of <code>Dataset</code> in Spark 1.6, <code>DataFrame</code> seems deprecated and won&apos;t be the focus of future developments of frameless. However, the design is interesting enough for being documented.</p>
<p>To safely manipulate <code>DataFrame</code>s we use a technique called <em>shadow type</em>, which consists in storing additional information about a value in a &quot;dummy&quot; type. Mirroring value-level computation at the type-level lets us leverage the type system to catch common mistakes at compile time.</p>
<h3 id="diving-in">Diving in</h3>
<p>In <code>TypedDataFrame</code>, we use a single <code>Schema &lt;: Product</code> to model the number, the types and the names of columns. Here is a what the definition of <code>TypedDataFrame</code> looks like, with simplified type signatures:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">import</span> org.apache.spark.sql.<span class="hljs-type">DataFrame</span>
<span class="hljs-keyword">import</span> shapeless.<span class="hljs-type">HList</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TDataFrame</span>[<span class="hljs-type">Schema</span> &lt;: <span class="hljs-type">Product</span>](<span class="hljs-params">df: <span class="hljs-type">DataFrame</span></span>) </span>{
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter</span></span>(predicate: <span class="hljs-type">Schema</span> =&gt; <span class="hljs-type">Boolean</span>): <span class="hljs-type">TDataFrame</span>[<span class="hljs-type">Schema</span>] = ???

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">select</span></span>[<span class="hljs-type">C</span> &lt;: <span class="hljs-type">HList</span>, <span class="hljs-type">Out</span> &lt;: <span class="hljs-type">Product</span>](columns: <span class="hljs-type">C</span>): <span class="hljs-type">TDataFrame</span>[<span class="hljs-type">Out</span>] = ???

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">innerJoin</span></span>[<span class="hljs-type">OtherS</span> &lt;: <span class="hljs-type">Product</span>, <span class="hljs-type">Out</span> &lt;: <span class="hljs-type">Product</span>]
    (other: <span class="hljs-type">TDataFrame</span>[<span class="hljs-type">OtherS</span>]): <span class="hljs-type">TDataFrame</span>[<span class="hljs-type">Out</span>] = ???

  <span class="hljs-comment">// Followed by equivalent of every DataFrame method with improved signature</span>
}
</code></pre>
<p>As you can see, instead of the <code>def filter(conditionExpr: String): DataFrame</code> defined in Spark, the <code>TypedDataFrame</code> version expects a function from <code>Schema</code> to <code>Boolean</code>, and models the fact that resulting <code>DataFrame</code> will still hold elements of type <code>Schema</code>.</p>
<h3 id="type-level-column-referencing">Type-level column referencing</h3>
<p>For Spark&apos;s <code>DataFrame</code>s, column referencing is done directly by <code>String</code>s or using the <code>Column</code> type which provides no additional type safety. <code>TypedDataFrame</code> improves on that by catching column referencing at compile type. When everything goes well, frameless select is very similar to vanilla select, except that it keeps track of the selected column types:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">import</span> frameless.<span class="hljs-type">TypedDataFrame</span>

<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Foo</span>(<span class="hljs-params">s: <span class="hljs-type">String</span>, d: <span class="hljs-type">Double</span>, i: <span class="hljs-type">Int</span></span>)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">selectIntString</span></span>(tf: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Foo</span>]): <span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)] =
  tf.select(<span class="hljs-symbol">&apos;i</span>, <span class="hljs-symbol">&apos;s</span>)
</code></pre>
<p>However, in case of typo, it gets coughs right away:</p>
<pre><code class="lang-scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">selectIntStringTypo</span></span>(tf: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Foo</span>]): <span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)] =
  tf.select(<span class="hljs-symbol">&apos;j</span>, <span class="hljs-symbol">&apos;s</span>)
</code></pre>
<h3 id="type-level-joins">Type-level joins</h3>
<p>Joins can available with two different syntaxes, the first lets you reference different columns on each <code>TypedDataFrame</code>, and ensures that their all exists and have compatible types:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Bar</span>(<span class="hljs-params">i: <span class="hljs-type">Int</span>, j: <span class="hljs-type">String</span>, b: <span class="hljs-type">Boolean</span></span>)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">join1</span></span>(tf1: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Foo</span>], tf2: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Bar</span>])
    : <span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">String</span>, <span class="hljs-type">Double</span>, <span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>, <span class="hljs-type">String</span>, <span class="hljs-type">Boolean</span>)] =
  tf1.innerJoin(tf2).on(<span class="hljs-symbol">&apos;s</span>).and(<span class="hljs-symbol">&apos;j</span>)
</code></pre>
<p>The second syntax bring some convenience when the joining columns have identical names in both tables:</p>
<pre><code class="lang-scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">join2</span></span>(tf1: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Foo</span>], tf2: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Bar</span>])
    : <span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">String</span>, <span class="hljs-type">Double</span>, <span class="hljs-type">Int</span>, <span class="hljs-type">String</span>, <span class="hljs-type">Boolean</span>)] =
  tf1.innerJoin(tf2).using(<span class="hljs-symbol">&apos;i</span>)
</code></pre>
<p>Further example are available in the <a href="../dataframe/src/test/scala/JoinTests.scala">TypedDataFrame join tests.</a></p>
<h3 id="complete-example">Complete example</h3>
<p>We now consider a complete example to see how the type system can frameless can improve not only correctness but also the readability of Spark jobs. Consider the following domain of phonebooks, city map and neighborhood:</p>
<pre><code class="lang-scala"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Neighborhood</span> </span>= <span class="hljs-type">String</span>
<span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Address</span> </span>= <span class="hljs-type">String</span>

<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PhoneBookEntry</span>(<span class="hljs-params">
  address: <span class="hljs-type">Address</span>,
  residents: <span class="hljs-type">String</span>,
  phoneNumber: <span class="hljs-type">Double</span>
</span>)</span>

<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CityMapEntry</span>(<span class="hljs-params">
  address: <span class="hljs-type">Address</span>,
  neighborhood: <span class="hljs-type">Neighborhood</span>
</span>)</span>
</code></pre>
<p>Our goal will be to compute the neighborhood with unique names, approximating &quot;unique&quot; with names containing less common
letters in the alphabet: &apos;x&apos;, &apos;q&apos;, and &apos;z&apos;. We are going to need a natural language processing library at some point, so
let&apos;s use the following for the example:</p>
<pre><code class="lang-scala"><span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">NLPLib</span> </span>{
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uniqueName</span></span>(name: <span class="hljs-type">String</span>): <span class="hljs-type">Boolean</span> = name.exists(<span class="hljs-type">Set</span>(&apos;x&apos;, &apos;q&apos;, &apos;z&apos;))
}
</code></pre>
<p>Suppose we manage to obtain a <code>TypedDataFrame[PhoneBookEntry]</code> and a <code>TypedDataFrame[CityMapEntry]</code> public data, here is what our Spark job could look like with frameless:</p>
<pre><code class="lang-scala"><span class="hljs-keyword">import</span> org.apache.spark.sql.<span class="hljs-type">SQLContext</span>

<span class="hljs-comment">// These case classes are used to hold intermediate results</span>
<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Family</span>(<span class="hljs-params">residents: <span class="hljs-type">String</span>, neighborhood: <span class="hljs-type">Neighborhood</span></span>)</span>
<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Person</span>(<span class="hljs-params">name: <span class="hljs-type">String</span>, neighborhood: <span class="hljs-type">Neighborhood</span></span>)</span>
<span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NeighborhoodCount</span>(<span class="hljs-params">neighborhood: <span class="hljs-type">Neighborhood</span>, count: <span class="hljs-type">Long</span></span>)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bestNeighborhood</span></span>
  (phoneBookTF: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">PhoneBookEntry</span>], cityMapTF: <span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">CityMapEntry</span>])
  (<span class="hljs-keyword">implicit</span> c: <span class="hljs-type">SQLContext</span>): <span class="hljs-type">String</span> = {
                                          (((((((((
  phoneBookTF
    .innerJoin(cityMapTF).using(<span class="hljs-symbol">&apos;address</span>) :<span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">Address</span>, <span class="hljs-type">String</span>, <span class="hljs-type">Double</span>, <span class="hljs-type">String</span>)])
    .select(<span class="hljs-symbol">&apos;_2</span>, <span class="hljs-symbol">&apos;_4</span>)                     :<span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">String</span>, <span class="hljs-type">String</span>)])
    .as[<span class="hljs-type">Family</span>]()                         :<span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Family</span>])
    .flatMap { f =&gt;
      f.residents.split(&apos; &apos;).map(r =&gt; <span class="hljs-type">Person</span>(r, f.neighborhood))
    }                                     :<span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Person</span>])
    .filter { p =&gt;
      <span class="hljs-type">NLPLib</span>.uniqueName(p.name)
    }                                     :<span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Person</span>])
    .groupBy(<span class="hljs-symbol">&apos;neighborhood</span>).count()       :<span class="hljs-type">TypedDataFrame</span>[(<span class="hljs-type">String</span>, <span class="hljs-type">Long</span>)])
    .as[<span class="hljs-type">NeighborhoodCount</span>]()              :<span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">NeighborhoodCount</span>])
    .sortDesc(<span class="hljs-symbol">&apos;count</span>)                     :<span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">NeighborhoodCount</span>])
    .select(<span class="hljs-symbol">&apos;neighborhood</span>)                :<span class="hljs-type">TypedDataFrame</span>[<span class="hljs-type">Tuple1</span>[<span class="hljs-type">String</span>]])
    .head._1
}
</code></pre>
<p>If you compare this version from Spark vanilla where every line is a <code>DataFrame</code>, you see how much types can improve readability. An executable version of this example is available in the <a href="../dataframe/src/test/scala/BestNeighborhood.scala">BestNeighborhood test</a>.</p>
<h3 id="limitations">Limitations</h3>
<p>The main limitation of this approach comes from Scala 2.10, which limits the arity of class classes to 22. Because of the way <code>DataFrame</code> models joins, joining two table with more that 11 fields results in a <code>DataFrame</code> which not representable with <code>Schema</code> of type <code>Product</code>.</p>
<p>In the <code>Dataset</code> API introduced in Spark 1.6, the way join are handled was rethought to return a pair of both schemas instead of a flat table, which moderates the trouble caused by case class limitations. Alternatively, since Scala 2.11, it is possible to define Tuple23 and onward. Sadly, due to the way Spark is commonly packaged in various systems, the amount Spark users having to Scala 2.11 and <em>not</em> to Spark 1.6 is essentially zero. For this reasons, further development in frameless will target Spark 1.6+, deprecating the early work on<code>TypedDataFrame</code>.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="Cats.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: Using Cats with RDDs">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Proof of Concept: TypedDataFrame","level":"1.8","depth":1,"previous":{"title":"Using Cats with RDDs","level":"1.7","depth":1,"path":"Cats.md","ref":"Cats.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"TypedDataFrame.md","mtime":"2017-05-23T08:58:07.647Z","type":"markdown"},"gitbook":{"version":"3.2.2","time":"2017-05-23T08:59:39.758Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

